# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eGkcecukP27hFT_X6iaIr3KyNJ_lPmGh
"""

#pip install pdfplumber

#pip install pypdf

import pandas as pd
import numpy as np
import seaborn as sns
from matplotlib import pyplot as plt
from pypdf import PdfReader, PdfWriter
import pdfplumber
import csv
import re
import os
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from statsmodels.tsa.arima.model import ARIMA
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords



# Ensure NLTK downloads are available
nltk_data_path = os.path.expanduser('~/AppData/Roaming/nltk_data')

if not os.path.exists(nltk_data_path):
    nltk.download('punkt')
    nltk.download('stopwords')

class AccountManagementAnalyzer:
    def __init__(self):
        self.df = None
        self.csv_file = None
        self.prediction_df = None

    def remove_pdf_password(self, input_pdf, password):
        output_pdf = os.path.splitext(input_pdf)[0] + "_unprotected.pdf"
        try:
            reader = PdfReader(input_pdf)
            if reader.decrypt(password) == 1:
                writer = PdfWriter()
                for page in reader.pages:
                    writer.add_page(page)
                with open(output_pdf, "wb") as f:
                    writer.write(f)
                print("Password removed successfully!")
                return output_pdf
            else:
                print("❌ Incorrect Password! Returning None.")
                return None 
        except Exception as e:
            print("An error occurred:", e)
            return None

    def analyze(self, pdf_path):
        try:
            default_csv_path = os.path.splitext(pdf_path)[0] + ".csv"
            with pdfplumber.open(pdf_path) as pdf, open(default_csv_path, "w", newline="") as f:
                writer = csv.writer(f)
                for page in pdf.pages:
                    table = page.extract_table()
                    if table:
                        writer.writerows(table)
            print("PDF converted to CSV successfully! Saved as:", default_csv_path)
            self.csv_file = default_csv_path
            return default_csv_path
        except Exception as e:
            print("An error occurred:", e)
            return None

    def show_data(self):
        self.df = pd.read_csv(self.csv_file)
        return self.df

    def info(self):
        return self.df.info()

    def naming_narration(self):
        self.df['Narration'] = self.df['Narration'].str.extract(r'UPI-([^-]+)', expand=False).str.strip().str.title()
        return self.df['Narration']

    def narration_csv(self):
        narration_file_path = "narration.csv"
        narration_df = pd.DataFrame(self.df['Narration'])
        narration_df.to_csv(narration_file_path, index=False)
        return narration_file_path

    def preprocessing_and_analysis(self):
       # global df
      # Include your data preprocessing and analysis code here
      self.df["Withdrawal Amount"] = pd.to_numeric(self.df["Withdrawal Amount"].str.replace(",", ""), errors="coerce").fillna(0)
      self.df["Deposit Amount"] = pd.to_numeric(self.df["Deposit Amount"].str.replace(",", ""), errors="coerce").fillna(0)
      self.df["Closing Balance*"] = pd.to_numeric(self.df["Closing Balance*"].str.replace(",", ""), errors="coerce")
      self.df["Date"] = pd.to_datetime(self.df["Date"], dayfirst=True)

      df_summary = self.df.groupby("Date").agg({"Withdrawal Amount": "sum", "Deposit Amount": "sum", "Closing Balance*": "last"}).reset_index()

      self.naming_narration()

      #plot daily withdrawl vs deposits --> 1

      sns.set(style="whitegrid")
      plt.figure(figsize=(12, 6))
      plt.plot(df_summary["Date"], df_summary["Withdrawal Amount"], marker="o", linestyle="-", label="Withdrawals", color="red")
      plt.plot(df_summary["Date"], df_summary["Deposit Amount"], marker="o", linestyle="-", label="Deposits", color="green")
      plt.xlabel("Date")
      plt.ylabel("Amount (₹)")
      plt.title("Daily Withdrawals and Deposits")
      plt.legend()
      plt.xticks(rotation=45)
      plt.savefig("static/graph1.png")
      plt.close()




      # total withdrawl vs deposits -- > 2

      plt.figure(figsize=(6, 6))
      plt.pie(
          [df_summary["Withdrawal Amount"].sum(), df_summary["Deposit Amount"].sum()],
          labels=["Withdrawals", "Deposits"],
          autopct="%1.1f%%",
          colors=["red", "green"],
          startangle=90,
      )
      plt.title("Total Withdrawals vs Deposits")
      plt.savefig("static/graph2.png")
      plt.close()


      # closing balance over time

      plt.figure(figsize=(12, 6))
      plt.plot(df_summary["Date"], df_summary["Closing Balance*"], marker="o", linestyle="-", color="blue")
      plt.xlabel("Date")
      plt.ylabel("Closing Balance (₹)")
      plt.title("Closing Balance Over Time")
      plt.xticks(rotation=45)
      plt.savefig("static/graph3.png")
      plt.close()


      # distribution of transaction amount

      plt.figure(figsize=(10, 5))
      sns.histplot(self.df["Withdrawal Amount"], bins=20, kde=True, color="red", label="Withdrawals")
      sns.histplot(self.df["Deposit Amount"], bins=20, kde=True, color="green", label="Deposits")
      plt.xlabel("Transaction Amount (₹)")
      plt.ylabel("Frequency")
      plt.title("Distribution of Transaction Amounts")
      plt.legend()
      plt.savefig("static/graph4.png")
      plt.close()


      # top 10 most frequent transaction

      top_narrations = self.df["Narration"].value_counts().nlargest(10)
      plt.figure(figsize=(10, 6))
      sns.barplot(y=top_narrations.index, x=top_narrations.values, palette="coolwarm")
      plt.xlabel("Frequency")
      plt.ylabel("Transaction Type")
      plt.title("Most Frequent Transactions (Top 10)")
      plt.savefig("static/graph5.png")
      plt.close()

      # top 10 withdrawl amounts


      narration_amounts = self.df.groupby("Narration")["Withdrawal Amount"].sum()


      top_narrations = narration_amounts.nlargest(10)

      plt.figure(figsize=(10, 6))
      ax = sns.barplot(y=top_narrations.index, x=top_narrations.values, palette="coolwarm")

      for i, amount in enumerate(top_narrations):
          ax.text(amount + 0.5, i, f"₹{amount:,.2f}", va="center", fontsize=12)

      plt.xlabel("Total Withdrawal Amount (₹)")
      plt.ylabel("Transaction Type")
      plt.title("Top 10 Transactions by Total Withdrawal Amount")
      plt.savefig("static/graph6.png")
      plt.close()

      # daily deposits and withdrawls


      df_summary = self.df.groupby("Date").agg(
          {"Deposit Amount": "sum", "Withdrawal Amount": "sum"}
      ).reset_index()

      plt.figure(figsize=(12, 6))
      bars_deposit = plt.bar(df_summary["Date"], df_summary["Deposit Amount"], color="green", label="Deposits")
      bars_withdrawal = plt.bar(df_summary["Date"], -df_summary["Withdrawal Amount"], color="red", label="Withdrawals")

      plt.axhline(0, color="black", linewidth=1.5)
      # Define font_size here
      font_size = 7
      def add_annotations(bars, is_deposit):
          for bar in bars:
              yval = bar.get_height()

              if abs(yval) < 200:
                  continue

              xval = bar.get_x() + bar.get_width() / 2


              vertical_offset = 15 if is_deposit else 25
              if is_deposit:
                  plt.text(xval, yval + vertical_offset, f"₹{yval:.2f}", ha='center', va='bottom', color="green", fontweight="bold", fontsize=font_size)
              else:
                  plt.text(xval, yval - vertical_offset, f"₹{-yval:.2f}", ha='center', va='top', color="red", fontweight="bold", fontsize=font_size)

      add_annotations(bars_deposit, is_deposit=True)
      add_annotations(bars_withdrawal, is_deposit=False)

      plt.yticks(
          [i for i in range(0, int(df_summary["Deposit Amount"].max()) + 5000, 5000)] +
          [-i for i in range(5000, 55000, 5000)]
      )

      plt.xlabel("Date")
      plt.ylabel("Amount (₹)")
      plt.title("Daily Deposits and Withdrawals")
      plt.legend()
      plt.xticks(rotation=45)

      plt.savefig("static/graph7.png")
      plt.close()

      # min max avg financial summary

      self.df.rename(columns={'Closing Balance*': 'Closing Balance'}, inplace=True)

      for col in ["Withdrawal Amount", "Deposit Amount", "Closing Balance"]:
          self.df[col] = self.df[col].astype(str).str.replace(",", "").astype(float)

      summary = self.df[["Withdrawal Amount", "Deposit Amount", "Closing Balance"]].describe()

      categories = ["Withdrawals", "Deposits", "Closing Balance"]
      averages = [summary.loc['mean', 'Withdrawal Amount'], summary.loc['mean', 'Deposit Amount'], summary.loc['mean', 'Closing Balance']]
      maximums = [summary.loc['max', 'Withdrawal Amount'], summary.loc['max', 'Deposit Amount'], summary.loc['max', 'Closing Balance']]
      minimums = [summary.loc['min', 'Withdrawal Amount'], summary.loc['min', 'Deposit Amount'], summary.loc['min', 'Closing Balance']]

      x = np.arange(len(categories))

      fig, ax = plt.subplots(figsize=(8, 5))
      bar_width = 0.25
      bars_avg = ax.bar(x - bar_width, averages, width=bar_width, label="Average", color='skyblue')
      bars_max = ax.bar(x, maximums, width=bar_width, label="Maximum", color='green')
      bars_min = ax.bar(x + bar_width, minimums, width=bar_width, label="Minimum", color='red')

      def add_labels(bars):
          for bar in bars:
              height = bar.get_height()
              ax.text(bar.get_x() + bar.get_width()/2, height, f"₹{height:.2f}", ha='center', va='bottom', fontsize=10, fontweight='bold')

      add_labels(bars_avg)
      add_labels(bars_max)
      add_labels(bars_min)

      ax.set_xticks(x)
      ax.set_xticklabels(categories, fontsize=12)
      ax.set_ylabel("Amount (₹)", fontsize=12)
      ax.set_title("Financial Summary - Withdrawals, Deposits, and Closing Balance", fontsize=14)
      ax.legend()
      ax.grid(axis='y', linestyle='--', alpha=0.7)

      plt.savefig("static/graph8.png")
      plt.close()
      pass


    nltk.download('punkt')
    nltk.download('stopwords')
    nltk.download('punkt_tab')
    def classification(self):
      # Include your transaction classification code here
      self.df['Narration'] = self.df['Narration'].astype(str).fillna('')

      categories = {
        "Food/Clothing": [
            "zomato", "swiggy", "flipkart", "groceries", "amazon", "myntra", "ajio","grofers",
            "nike", "adidas", "zepto", "bigbasket", "dmart", "reliance fresh", "spencers", "foodpanda",
            "kfc", "mcdonalds", "dominos", "pizzahut", "subway", "burger king", "fbb", "pantaloons", "westside"
        ],
        "Entertainment": [
            "netflix", "prime", "hotstar", "spotify", "google", "book my show", "jiocinema",
            "hulu", "disney", "sony liv", "voot", "zee5", "itunes", "youtube premium", "audible", "gaana", "wynk"
        ],
        "Recharge": [
            "airtel", "jio", "vodafone", "bsnl", "recharge", "top-up", "vi", "talktime", "prepaid", "postpaid",
            "mobile recharge", "phonepe recharge", "paytm recharge"
        ],
        "Rent/Bills": [
            "electricity", "water bill", "rent", "utility", "phonepe", "bbpsbp", "landlord",
            "property tax", "maintenance", "gas bill", "internet bill", "dth recharge", "municipal tax"
        ],
        "Transport": [
            "rapido", "ola", "uber", "metro", "rail", "bus", "flight", "taxi", "redbus", "irctc",
            "indigo", "air india", "spicejet", "go air", "blablacar", "cab", "rickshaw", "fuel", "petrol", "diesel"
        ],
        "Emergency": [
            "hospital", "doctor", "medical", "pharmacy", "cash deposit", "emergency", "ambulance",
            "surgery", "clinic", "meds", "medlife", "pharmeasy", "apollo", "fortis", "max healthcare"
        ],
        "Banking": [
            "airtel payments bank", "navi technologies", "banking", "loan", "credit card", "debit card",
            "upi", "neft", "imps", "rtgs", "interest", "savings", "hdfc", "icici", "sbi", "axis bank", "kotak"
        ],
        "Gaming": [
            "steam", "epic games", "pubg", "game", "valorant", "counter strike", "call of duty", "roblox",
            "playstation", "xbox", "nintendo", "esports", "minecraft", "rummy", "poker", "fantasy cricket"
        ],
        "Trading": [
            "zerodha", "upstox", "angel broking", "groww", "stocks", "equity", "mutual funds",
            "investment", "bonds", "nse", "bse", "cryptocurrency", "bitcoin", "forex", "commodities", "shares"
        ],
        "Personal Transfer": []  #
      }
      stop_words = set(stopwords.words('english'))



      #classify transaction
      def classify_transaction(text):
        text = text.lower()
        words = word_tokenize(text)
        words = [word for word in words if word.isalnum() and word not in stop_words]

        for category, keywords in categories.items():
            if any(keyword in text for keyword in keywords):
                return category

        return "Personal Transfer"



      self.df['Category'] = self.df['Narration'].apply(classify_transaction)

      self.df.to_csv("classified_narrations.csv", index=False)

      self.df
      #np.savetxt("classified_narrations.csv", self.df.values, delimiter=",", fmt="%s")


      category_counts = self.df['Category'].value_counts()

      colors = sns.color_palette("pastel")

      plt.figure(figsize=(10, 6))
      plt.pie(
          category_counts,
          labels=category_counts.index,
          autopct='%1.1f%%',
          colors=colors,
          startangle=140,
          wedgeprops={'edgecolor': 'black'}
      )

      plt.title("Transaction Category Distribution")

      plt.savefig("static/graph9.png")
      plt.close()

      pass

    def trans_pred(self, future_days=30):
        # Include your transaction prediction code here

      #global df, prediction_df

      # processing the data around the dates
      self.df["Date"] = pd.to_datetime(self.df["Date"], format="%d/%m/%Y")

      self.df["Withdrawal Amount"] = pd.to_numeric(self.df["Withdrawal Amount"].astype(str).replace(",", ""), errors="coerce").fillna(0).astype(float)
      self.df["Deposit Amount"] = pd.to_numeric(self.df["Deposit Amount"].astype(str).replace(",", ""), errors="coerce").fillna(0).astype(float)
      self.df["Closing Balance"] = pd.to_numeric(self.df["Closing Balance"].astype(str).replace(",", ""), errors="coerce").fillna(0).astype(float)


      # Sort by Date
      self.df = self.df.sort_values("Date")

      # Create time series data
      data = self.df[["Closing Balance"]].values
      scaler = MinMaxScaler(feature_range=(0, 1))
      data_scaled = scaler.fit_transform(data)

      # LSTM MODEL
      def create_sequences(data, seq_length):
          X, y = [], []
          for i in range(len(data) - seq_length):
              X.append(data[i:i+seq_length])
              y.append(data[i+seq_length])
          return np.array(X), np.array(y)

      # sequence
      seq_length = 5  # Use past 5 days to predict next day
      X, y = create_sequences(data_scaled, seq_length)


      # Train-test split
      train_size = int(len(X) * 0.8)
      X_train, y_train = X[:train_size], y[:train_size]
      X_test, y_test = X[train_size:], y[train_size:]

      # LSTM Model
      model = Sequential([
          LSTM(50, return_sequences=True, input_shape=(seq_length, 1)),
          LSTM(50),
          Dense(1)
      ])
      model.compile(optimizer='adam', loss='mse')
      model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=1)


      # Predict future balance
      predictions = []
      last_sequence = X_test[-1]
      for _ in range(future_days):
          next_day_pred = model.predict(last_sequence.reshape(1, seq_length, 1))
          predictions.append(next_day_pred[0, 0])
          last_sequence = np.vstack((last_sequence[1:], next_day_pred))

      predicted_values = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))



      # ARIMA Model
      model_arima = ARIMA(self.df["Closing Balance"], order=(5,1,0))
      model_arima_fit = model_arima.fit()
      forecast_arima = model_arima_fit.forecast(steps=future_days)


      # Prepare future dataframe
      dates_future = pd.date_range(self.df["Date"].iloc[-1], periods=future_days+1)[1:]
      prediction_df = pd.DataFrame({
          "Date": dates_future,
          "LSTM_Prediction": predicted_values.flatten(),
          "ARIMA_Prediction": forecast_arima
      })

      self.prediction_df = prediction_df

      # comparing both model and predict balance after n days
      current_balance = self.df["Closing Balance"].iloc[-1]

      print(f"Current Balance: ₹{current_balance:.2f}")
      print("\nFuture Predictions (ARIMA & LSTM):\n", self.prediction_df)
      
      # analysing error of model
      actual_balances = scaler.inverse_transform(y_test)
      lstm_predictions = scaler.inverse_transform(model.predict(X_test))
      
      # Slice the forecast to match the length of the test set for metric calculation
      arima_predictions_for_metrics = forecast_arima[:len(y_test)]
      
      # Ensure arrays for metrics have the same size to avoid broadcasting errors
      metric_len = len(arima_predictions_for_metrics)
      actual_balances_flat = actual_balances.flatten()[:metric_len]
      lstm_predictions_flat = lstm_predictions.flatten()[:metric_len]

      msme_lstm = np.mean((actual_balances_flat - lstm_predictions_flat) ** 2) / np.mean(actual_balances_flat ** 2)
      msme_arima = np.mean((actual_balances_flat - arima_predictions_for_metrics) ** 2) / np.mean(actual_balances_flat ** 2)

      from sklearn.metrics import mean_absolute_error
      mae_lstm = mean_absolute_error(actual_balances_flat, lstm_predictions_flat)
      rmae_lstm = mae_lstm / np.mean(actual_balances_flat)

      mae_arima = mean_absolute_error(actual_balances_flat, arima_predictions_for_metrics)
      rmae_arima = mae_arima / np.mean(actual_balances_flat)

      print(f"MSME_LSTM:{msme_lstm}")
      print(f"MSME_ARIMA:{msme_arima}")
      print(f"RMAE_LSTM:{rmae_lstm}")
      print(f"RMAE_ARIMA:{rmae_arima}")

      return current_balance, self.prediction_df

    def budget_system(self):
      # Include your budgeting system code here

      #global prediction_df
    # setting the classification dataset

      cat = pd.read_csv("classified_narrations.csv") # add header=None
      column_names = ["Date", "Narration", "Chq. / Ref No.", "Value Date",
                      "Withdrawal Amount", "Deposit Amount", "Closing Balance", "Category"]



      # Rename columns for clarity
      cat.columns = column_names


      # model mean (ARIMA and LSTM)
      self.prediction_df["LSTM_Prediction"] = pd.to_numeric(self.prediction_df["LSTM_Prediction"], errors='coerce')  # Convert to numeric, handle errors
      self.prediction_df["ARIMA_Prediction"] = pd.to_numeric(self.prediction_df["ARIMA_Prediction"], errors='coerce')

      predicted_income = self.prediction_df["LSTM_Prediction"].mean()
      predicted_expense = self.prediction_df["ARIMA_Prediction"].mean()


      # AI-Based Budgeting Breakdown
      predicted_savings = predicted_income * 0.2  # 20% of income as savings
      essential_expense_pred = predicted_expense * 0.7  # 70% on essentials
      non_essential_expense_pred = predicted_expense * 0.3  # 30% on non-essentials

      # personal transfer not required
      filtered_df = cat[cat["Category"] != "Personal Transfer"]

      # Use 'Withdrawal Amount' instead of 'Withdrawal_Amount'
      category_expense = filtered_df.groupby("Category")["Withdrawal Amount"].sum()

      # setting the past expense and predicted expense
      past_expense_ratio = category_expense / category_expense.sum()
      adaptive_allocation = predicted_expense * past_expense_ratio

      # conditions for expense (predicted and actual)
      if predicted_expense > predicted_income * 0.8:
        savings_ratio = 0.1
      else:
          savings_ratio = 0.2

      dynamic_savings = predicted_income * savings_ratio
      essential_expense = predicted_expense * 0.7
      non_essential_expense = predicted_expense * 0.3

      # Expense Breakdown by Category bar plot
      plt.figure(figsize=(8, 6))
      category_expense.plot(kind="bar", color="skyblue")
      plt.title("Expense Breakdown by Category (Excluding Transfers)")
      plt.ylabel("Amount (₹)")
      plt.xticks(rotation=45)
      plt.tight_layout()
      plt.savefig("static/graph10.png")
      plt.close()

      # pie chart of budget allocation
      plt.figure(figsize=(6, 6))
      plt.pie([dynamic_savings, essential_expense, non_essential_expense],
              labels=["Savings", "Essentials", "Non-Essentials"],
              autopct="%.1f%%", colors=["green", "red", "orange"])
      plt.title("Budget Allocation")
      plt.savefig("static/graph11.png")
      plt.close()

      # Check for overspending to generate warnings
      over_spending = adaptive_allocation[adaptive_allocation > category_expense]
      over_spending_dict = over_spending.to_dict() if not over_spending.empty else None
      
      income_warning = None
      if predicted_expense > predicted_income:
          overspending_amount = predicted_expense - predicted_income
          income_warning = f"Warning: Your predicted expenses exceed your income by ₹{overspending_amount:.2f}. Consider reducing discretionary spending."

      # Return a dictionary with all budget details
      return {
          'predicted_income': predicted_income,
          'predicted_expense': predicted_expense,
          'savings_ratio': savings_ratio,
          'dynamic_savings': dynamic_savings,
          'essential_expense': essential_expense,
          'non_essential_expense': non_essential_expense,
          'category_expense': category_expense.to_dict(),
          'adaptive_allocation': adaptive_allocation.to_dict(),
          'over_spending': over_spending_dict,
          'income_warning': income_warning
      }

if __name__ == "__main__":
    analyzer = AccountManagementAnalyzer()
    unprotected_pdf = analyzer.remove_pdf_password()
    if unprotected_pdf:
        csv_file = analyzer.anal(unprotected_pdf)
        if csv_file:
            analyzer.show_data()
            analyzer.preprocessing_and_analysis()
            analyzer.classification()
            analyzer.trans_pred()
            analyzer.budget_system()